{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "#ADNI MERGE FINAL with RAW DX"
      ],
      "metadata": {
        "id": "_wtBGWM6TiwK"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**XGBoost:**"
      ],
      "metadata": {
        "id": "ok3GLn01U3ST"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import LabelEncoder, OrdinalEncoder\n",
        "from sklearn.impute import SimpleImputer\n",
        "from sklearn.compose import ColumnTransformer\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.metrics import classification_report, accuracy_score\n",
        "from xgboost import XGBClassifier\n",
        "from joblib import dump\n",
        "\n",
        "# =========================================================\n",
        "# 1. Load data\n",
        "# =========================================================\n",
        "csv_path = \"ADNI_MERGE_FINAL_with_RAW_DX.csv\"   # put the CSV in the same folder or give full path\n",
        "df = pd.read_csv(csv_path)\n",
        "\n",
        "print(\"Shape:\", df.shape)\n",
        "print(\"Columns:\", list(df.columns))\n",
        "\n",
        "# =========================================================\n",
        "# 2. Choose target column & drop ID-like columns from features\n",
        "# =========================================================\n",
        "# Use DX as the label (change to \"DIAGNOSIS\" if you prefer)\n",
        "TARGET_COL = \"DX\"\n",
        "\n",
        "# Some columns that are clearly IDs / meta and shouldn't be used as predictors\n",
        "ID_COLUMNS = [\n",
        "    \"RID\", \"PTID\", \"RID.1\", \"ID\", \"SITEID\", \"USERDATE2\"\n",
        "]\n",
        "\n",
        "# Keep only those ID columns that actually exist in the dataframe\n",
        "id_cols_present = [c for c in ID_COLUMNS if c in df.columns]\n",
        "\n",
        "# Separate X and y\n",
        "y = df[TARGET_COL]\n",
        "X = df.drop(columns=[TARGET_COL] + id_cols_present)\n",
        "\n",
        "print(\"Features shape:\", X.shape)\n",
        "print(\"Target value counts:\")\n",
        "print(y.value_counts())\n",
        "\n",
        "# =========================================================\n",
        "# 3. Encode target labels (handles string labels like CN/MCI/AD)\n",
        "# =========================================================\n",
        "label_encoder = LabelEncoder()\n",
        "y_enc = label_encoder.fit_transform(y)\n",
        "\n",
        "num_classes = len(label_encoder.classes_)\n",
        "print(\"Number of classes in target:\", num_classes)\n",
        "print(\"Classes:\", label_encoder.classes_)\n",
        "\n",
        "# Decide XGBoost objective based on number of classes\n",
        "if num_classes <= 2:\n",
        "    objective = \"binary:logistic\"\n",
        "    eval_metric = \"logloss\"\n",
        "else:\n",
        "    objective = \"multi:softprob\"\n",
        "    eval_metric = \"mlogloss\"\n",
        "\n",
        "# =========================================================\n",
        "# 4. Split into train / test\n",
        "# =========================================================\n",
        "X_train, X_test, y_train, y_test = train_test_split(\n",
        "    X,\n",
        "    y_enc,\n",
        "    test_size=0.2,\n",
        "    random_state=42,\n",
        "    stratify=y_enc  # preserves class distribution\n",
        ")\n",
        "\n",
        "# =========================================================\n",
        "# 5. Build preprocessing for numeric & categorical features\n",
        "# =========================================================\n",
        "numeric_cols = X.select_dtypes(include=[\"number\"]).columns.tolist()\n",
        "categorical_cols = X.select_dtypes(exclude=[\"number\"]).columns.tolist()\n",
        "\n",
        "print(\"Numeric columns:\", len(numeric_cols))\n",
        "print(\"Categorical columns:\", len(categorical_cols))\n",
        "\n",
        "numeric_transformer = SimpleImputer(strategy=\"median\")\n",
        "\n",
        "categorical_transformer = Pipeline(\n",
        "    steps=[\n",
        "        (\"imputer\", SimpleImputer(strategy=\"most_frequent\")),\n",
        "        (\"encoder\", OrdinalEncoder(handle_unknown=\"use_encoded_value\", unknown_value=-1)),\n",
        "    ]\n",
        ")\n",
        "\n",
        "preprocessor = ColumnTransformer(\n",
        "    transformers=[\n",
        "        (\"num\", numeric_transformer, numeric_cols),\n",
        "        (\"cat\", categorical_transformer, categorical_cols),\n",
        "    ]\n",
        ")\n",
        "\n",
        "# =========================================================\n",
        "# 6. Define XGBoost model\n",
        "# =========================================================\n",
        "xgb_params = dict(\n",
        "    n_estimators=500,\n",
        "    learning_rate=0.05,\n",
        "    max_depth=5,\n",
        "    subsample=0.8,\n",
        "    colsample_bytree=0.8,\n",
        "    objective=objective,\n",
        "    eval_metric=eval_metric,\n",
        "    tree_method=\"hist\",   # fast on CPU; use \"gpu_hist\" if you have GPU\n",
        "    n_jobs=-1,\n",
        "    random_state=42,\n",
        ")\n",
        "\n",
        "if num_classes > 2:\n",
        "    xgb_params[\"num_class\"] = num_classes\n",
        "\n",
        "xgb_model = XGBClassifier(**xgb_params)\n",
        "\n",
        "# Full pipeline: preprocessing + model\n",
        "clf = Pipeline(\n",
        "    steps=[\n",
        "        (\"preprocess\", preprocessor),\n",
        "        (\"model\", xgb_model),\n",
        "    ]\n",
        ")\n",
        "\n",
        "# =========================================================\n",
        "# 7. Train\n",
        "# =========================================================\n",
        "print(\"\\nTraining XGBoost model...\")\n",
        "clf.fit(X_train, y_train)\n",
        "\n",
        "# =========================================================\n",
        "# 8. Evaluate\n",
        "# =========================================================\n",
        "print(\"\\nEvaluating on test set...\")\n",
        "y_pred_enc = clf.predict(X_test)\n",
        "y_pred_labels = label_encoder.inverse_transform(y_pred_enc)\n",
        "y_test_labels = label_encoder.inverse_transform(y_test)\n",
        "\n",
        "print(\"\\nAccuracy:\", accuracy_score(y_test, y_pred_enc))\n",
        "\n",
        "print(\"\\nClassification report (per class):\")\n",
        "print(classification_report(\n",
        "    y_test,\n",
        "    y_pred_enc,\n",
        "    target_names=label_encoder.classes_\n",
        "))\n",
        "\n",
        "# =========================================================\n",
        "# 9. Save model + label encoder\n",
        "# =========================================================\n",
        "dump(clf, \"adni_xgb_pipeline.joblib\")\n",
        "dump(label_encoder, \"adni_label_encoder.joblib\")\n",
        "print(\"\\nSaved pipeline to 'adni_xgb_pipeline.joblib' and label encoder to 'adni_label_encoder.joblib'.\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8xJkT9YFLBmr",
        "outputId": "551cbd71-4542-41ef-b4cf-018d7cb4e7d9"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Shape: (16420, 151)\n",
            "Columns: ['RID', 'PTID', 'COLPROT', 'ORIGPROT', 'EXAMDATE', 'DX_bl', 'APOE4', 'AV45', 'CDRSB_x', 'DIGITSCOR', 'EcogPtMem', 'EcogSPMem', 'EcogSPLang', 'EcogSPVisspat', 'EcogSPPlan', 'EcogSPOrgan', 'EcogSPDivatt', 'EcogSPTotal', 'FLDSTRENG', 'FSVERSION', 'Hippocampus', 'WholeBrain', 'Entorhinal', 'Fusiform', 'ICV', 'DX', 'DIGITSCOR_bl', 'mPACCtrailsB_bl', 'Ventricles_bl', 'WholeBrain_bl', 'Fusiform_bl', 'MOCA_bl', 'EcogPtMem_bl', 'EcogPtLang_bl', 'EcogPtPlan_bl', 'EcogPtOrgan_bl', 'EcogPtDivatt_bl', 'EcogPtTotal_bl', 'EcogSPMem_bl', 'EcogSPLang_bl', 'EcogSPVisspat_bl', 'EcogSPPlan_bl', 'EcogSPOrgan_bl', 'EcogSPDivatt_bl', 'EcogSPTotal_bl', 'ABETA_bl', 'PIB_bl', 'AV45_bl', 'Years_bl', 'Month_bl', 'PTETHCAT_Not Hisp/Latino', 'PTRACCAT_Asian', 'PTRACCAT_Black', 'PTRACCAT_White', 'GENOTYPE', 'APTESTDT', 'APVOLUME', 'APRECEIVE', 'APAMBTEMP', 'RID.1', 'PHC_Visit', 'PHC_Age_Cognition', 'PHC_Diagnosis', 'PHC_Sex', 'PHC_Race', 'PHC_Ethnicity', 'PHC_Education', 'PHC_MEM', 'PHC_MEM_SE', 'PHC_MEM_PreciseFilter', 'PHC_EXF', 'PHC_EXF_SE', 'PHC_EXF_PreciseFilter', 'PHC_LAN', 'PHC_LAN_SE', 'PHC_LAN_PreciseFilter', 'PHC_VSP', 'PHC_VSP_SE', 'PHC_VSP_PreciseFilter', 'PTSOURCE', 'PTGENDER', 'PTDOBYY', 'PTHAND', 'PTEDUCAT', 'PTWORKHS', 'PTWORK', 'PTHOME', 'PTTLANG', 'PTPLANG', 'PTADBEG', 'PTCOGBEG', 'PTETHCAT', 'PTRACCAT', 'PTCLANG', 'PTLANGSP', 'PTLANGWR', 'PTSPOTTIM', 'PTLANGPR1', 'PTLANGUN1', 'PTLANGPR4', 'PTLANGRD4', 'PTLANGUN4', 'PTLANGSP5', 'PTLANGTTL', 'PTETHCATH', 'PTIMMAGE', 'PTIMMWHY', 'PTBIRGR', 'ID', 'SITEID', 'USERDATE2', 'HAS_QC_ERROR_x', 'DIAGNOSIS', 'DXNORM', 'DXNODEP', 'DXMCI', 'DXMDES', 'DXMPTR1', 'DXMPTR2', 'DXMPTR3', 'DXMPTR4', 'DXMPTR5', 'DXMPTR6', 'DXMDUE', 'DXMOTHET', 'DXDSEV', 'DXDDUE', 'DXAD', 'DXAPP', 'DXAPROB', 'DXAPOSS', 'DXPARK', 'DXPDES', 'DXPCOG', 'DXPATYP', 'DXDEP', 'DXOTHDEM', 'DXODES', 'DXCONFID', 'HAS_QC_ERROR_y', 'CDSOURCE', 'CDVERSION', 'CDMEMORY', 'CDORIENT', 'CDJUDGE', 'CDCOMMUN', 'CDHOME', 'CDCARE', 'CDGLOBAL', 'CDRSB_y', 'HAS_QC_ERROR']\n",
            "Features shape: (16420, 144)\n",
            "Target value counts:\n",
            "DX\n",
            "MCI         9951\n",
            "CN          4020\n",
            "Dementia    2449\n",
            "Name: count, dtype: int64\n",
            "Number of classes in target: 3\n",
            "Classes: ['CN' 'Dementia' 'MCI']\n",
            "Numeric columns: 139\n",
            "Categorical columns: 5\n",
            "\n",
            "Training XGBoost model...\n",
            "\n",
            "Evaluating on test set...\n",
            "\n",
            "Accuracy: 0.9461023142509135\n",
            "\n",
            "Classification report (per class):\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "          CN       0.94      0.94      0.94       804\n",
            "    Dementia       0.91      0.92      0.92       490\n",
            "         MCI       0.96      0.95      0.96      1990\n",
            "\n",
            "    accuracy                           0.95      3284\n",
            "   macro avg       0.94      0.94      0.94      3284\n",
            "weighted avg       0.95      0.95      0.95      3284\n",
            "\n",
            "\n",
            "Saved pipeline to 'adni_xgb_pipeline.joblib' and label encoder to 'adni_label_encoder.joblib'.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Random Forest:**"
      ],
      "metadata": {
        "id": "Y9olxmFNU5Ub"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import LabelEncoder, OrdinalEncoder\n",
        "from sklearn.impute import SimpleImputer\n",
        "from sklearn.compose import ColumnTransformer\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.metrics import classification_report, accuracy_score\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from joblib import dump\n",
        "\n",
        "# =========================================================\n",
        "# 1. Load data\n",
        "# =========================================================\n",
        "csv_path = \"ADNI_MERGE_FINAL_with_RAW_DX.csv\"\n",
        "df = pd.read_csv(csv_path)\n",
        "\n",
        "print(\"Shape:\", df.shape)\n",
        "print(\"Columns:\", list(df.columns))\n",
        "\n",
        "# =========================================================\n",
        "# 2. Target + drop ID-like columns\n",
        "# =========================================================\n",
        "TARGET_COL = \"DX\"\n",
        "\n",
        "ID_COLUMNS = [\n",
        "    \"RID\", \"PTID\", \"RID.1\", \"ID\", \"SITEID\", \"USERDATE2\"\n",
        "]\n",
        "\n",
        "id_cols_present = [c for c in ID_COLUMNS if c in df.columns]\n",
        "\n",
        "y = df[TARGET_COL]\n",
        "X = df.drop(columns=[TARGET_COL] + id_cols_present)\n",
        "\n",
        "print(\"Features shape:\", X.shape)\n",
        "print(\"Target value counts:\")\n",
        "print(y.value_counts())\n",
        "\n",
        "# =========================================================\n",
        "# 3. Encode target (DX)\n",
        "# =========================================================\n",
        "label_encoder = LabelEncoder()\n",
        "y_enc = label_encoder.fit_transform(y)\n",
        "\n",
        "print(\"Number of classes:\", len(label_encoder.classes_))\n",
        "print(\"Classes:\", label_encoder.classes_)\n",
        "\n",
        "# =========================================================\n",
        "# 4. Train / test split\n",
        "# =========================================================\n",
        "X_train, X_test, y_train, y_test = train_test_split(\n",
        "    X,\n",
        "    y_enc,\n",
        "    test_size=0.2,\n",
        "    random_state=42,\n",
        "    stratify=y_enc\n",
        ")\n",
        "\n",
        "# =========================================================\n",
        "# 5. Preprocessing: numeric & categorical\n",
        "# =========================================================\n",
        "numeric_cols = X.select_dtypes(include=[\"number\"]).columns.tolist()\n",
        "categorical_cols = X.select_dtypes(exclude=[\"number\"]).columns.tolist()\n",
        "\n",
        "print(\"Numeric columns:\", len(numeric_cols))\n",
        "print(\"Categorical columns:\", len(categorical_cols))\n",
        "\n",
        "numeric_transformer = SimpleImputer(strategy=\"median\")\n",
        "\n",
        "categorical_transformer = Pipeline(\n",
        "    steps=[\n",
        "        (\"imputer\", SimpleImputer(strategy=\"most_frequent\")),\n",
        "        (\"encoder\", OrdinalEncoder(handle_unknown=\"use_encoded_value\", unknown_value=-1)),\n",
        "    ]\n",
        ")\n",
        "\n",
        "preprocessor = ColumnTransformer(\n",
        "    transformers=[\n",
        "        (\"num\", numeric_transformer, numeric_cols),\n",
        "        (\"cat\", categorical_transformer, categorical_cols),\n",
        "    ]\n",
        ")\n",
        "\n",
        "# =========================================================\n",
        "# 6. Random Forest model\n",
        "# =========================================================\n",
        "rf_model = RandomForestClassifier(\n",
        "    n_estimators=300,\n",
        "    max_depth=None,          # let trees grow fully; you can tune this\n",
        "    min_samples_split=2,\n",
        "    min_samples_leaf=1,\n",
        "    max_features=\"sqrt\",\n",
        "    n_jobs=-1,\n",
        "    random_state=42,\n",
        "    class_weight=\"balanced\"  # helps if classes are imbalanced\n",
        ")\n",
        "\n",
        "clf = Pipeline(\n",
        "    steps=[\n",
        "        (\"preprocess\", preprocessor),\n",
        "        (\"model\", rf_model),\n",
        "    ]\n",
        ")\n",
        "\n",
        "# =========================================================\n",
        "# 7. Train\n",
        "# =========================================================\n",
        "print(\"\\nTraining Random Forest on ADNI_MERGE_FINAL_with_RAW_DX.csv ...\")\n",
        "clf.fit(X_train, y_train)\n",
        "\n",
        "# =========================================================\n",
        "# 8. Evaluate\n",
        "# =========================================================\n",
        "y_pred = clf.predict(X_test)\n",
        "\n",
        "print(\"\\nAccuracy:\", accuracy_score(y_test, y_pred))\n",
        "print(\"\\nClassification report:\")\n",
        "print(\n",
        "    classification_report(\n",
        "        y_test,\n",
        "        y_pred,\n",
        "        target_names=label_encoder.classes_\n",
        "    )\n",
        ")\n",
        "\n",
        "# =========================================================\n",
        "# 9. Save model + encoder\n",
        "# =========================================================\n",
        "dump(clf, \"rf_adni_raw_dx_pipeline.joblib\")\n",
        "dump(label_encoder, \"rf_adni_raw_dx_label_encoder.joblib\")\n",
        "print(\"\\nSaved pipeline to 'rf_adni_raw_dx_pipeline.joblib' and label encoder to 'rf_adni_raw_dx_label_encoder.joblib'.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9fyppn6lU8ov",
        "outputId": "5bdccfe8-7ee3-4acd-b034-2745949c9f5e"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Shape: (16420, 151)\n",
            "Columns: ['RID', 'PTID', 'COLPROT', 'ORIGPROT', 'EXAMDATE', 'DX_bl', 'APOE4', 'AV45', 'CDRSB_x', 'DIGITSCOR', 'EcogPtMem', 'EcogSPMem', 'EcogSPLang', 'EcogSPVisspat', 'EcogSPPlan', 'EcogSPOrgan', 'EcogSPDivatt', 'EcogSPTotal', 'FLDSTRENG', 'FSVERSION', 'Hippocampus', 'WholeBrain', 'Entorhinal', 'Fusiform', 'ICV', 'DX', 'DIGITSCOR_bl', 'mPACCtrailsB_bl', 'Ventricles_bl', 'WholeBrain_bl', 'Fusiform_bl', 'MOCA_bl', 'EcogPtMem_bl', 'EcogPtLang_bl', 'EcogPtPlan_bl', 'EcogPtOrgan_bl', 'EcogPtDivatt_bl', 'EcogPtTotal_bl', 'EcogSPMem_bl', 'EcogSPLang_bl', 'EcogSPVisspat_bl', 'EcogSPPlan_bl', 'EcogSPOrgan_bl', 'EcogSPDivatt_bl', 'EcogSPTotal_bl', 'ABETA_bl', 'PIB_bl', 'AV45_bl', 'Years_bl', 'Month_bl', 'PTETHCAT_Not Hisp/Latino', 'PTRACCAT_Asian', 'PTRACCAT_Black', 'PTRACCAT_White', 'GENOTYPE', 'APTESTDT', 'APVOLUME', 'APRECEIVE', 'APAMBTEMP', 'RID.1', 'PHC_Visit', 'PHC_Age_Cognition', 'PHC_Diagnosis', 'PHC_Sex', 'PHC_Race', 'PHC_Ethnicity', 'PHC_Education', 'PHC_MEM', 'PHC_MEM_SE', 'PHC_MEM_PreciseFilter', 'PHC_EXF', 'PHC_EXF_SE', 'PHC_EXF_PreciseFilter', 'PHC_LAN', 'PHC_LAN_SE', 'PHC_LAN_PreciseFilter', 'PHC_VSP', 'PHC_VSP_SE', 'PHC_VSP_PreciseFilter', 'PTSOURCE', 'PTGENDER', 'PTDOBYY', 'PTHAND', 'PTEDUCAT', 'PTWORKHS', 'PTWORK', 'PTHOME', 'PTTLANG', 'PTPLANG', 'PTADBEG', 'PTCOGBEG', 'PTETHCAT', 'PTRACCAT', 'PTCLANG', 'PTLANGSP', 'PTLANGWR', 'PTSPOTTIM', 'PTLANGPR1', 'PTLANGUN1', 'PTLANGPR4', 'PTLANGRD4', 'PTLANGUN4', 'PTLANGSP5', 'PTLANGTTL', 'PTETHCATH', 'PTIMMAGE', 'PTIMMWHY', 'PTBIRGR', 'ID', 'SITEID', 'USERDATE2', 'HAS_QC_ERROR_x', 'DIAGNOSIS', 'DXNORM', 'DXNODEP', 'DXMCI', 'DXMDES', 'DXMPTR1', 'DXMPTR2', 'DXMPTR3', 'DXMPTR4', 'DXMPTR5', 'DXMPTR6', 'DXMDUE', 'DXMOTHET', 'DXDSEV', 'DXDDUE', 'DXAD', 'DXAPP', 'DXAPROB', 'DXAPOSS', 'DXPARK', 'DXPDES', 'DXPCOG', 'DXPATYP', 'DXDEP', 'DXOTHDEM', 'DXODES', 'DXCONFID', 'HAS_QC_ERROR_y', 'CDSOURCE', 'CDVERSION', 'CDMEMORY', 'CDORIENT', 'CDJUDGE', 'CDCOMMUN', 'CDHOME', 'CDCARE', 'CDGLOBAL', 'CDRSB_y', 'HAS_QC_ERROR']\n",
            "Features shape: (16420, 144)\n",
            "Target value counts:\n",
            "DX\n",
            "MCI         9951\n",
            "CN          4020\n",
            "Dementia    2449\n",
            "Name: count, dtype: int64\n",
            "Number of classes: 3\n",
            "Classes: ['CN' 'Dementia' 'MCI']\n",
            "Numeric columns: 139\n",
            "Categorical columns: 5\n",
            "\n",
            "Training Random Forest on ADNI_MERGE_FINAL_with_RAW_DX.csv ...\n",
            "\n",
            "Accuracy: 0.9403166869671132\n",
            "\n",
            "Classification report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "          CN       0.94      0.94      0.94       804\n",
            "    Dementia       0.92      0.89      0.90       490\n",
            "         MCI       0.95      0.95      0.95      1990\n",
            "\n",
            "    accuracy                           0.94      3284\n",
            "   macro avg       0.93      0.93      0.93      3284\n",
            "weighted avg       0.94      0.94      0.94      3284\n",
            "\n",
            "\n",
            "Saved pipeline to 'rf_adni_raw_dx_pipeline.joblib' and label encoder to 'rf_adni_raw_dx_label_encoder.joblib'.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#ADNI MERGE Processed"
      ],
      "metadata": {
        "id": "hgzDWMm2Tdfs"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**XGBoost:**"
      ],
      "metadata": {
        "id": "FiffhZeXUuF8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import LabelEncoder, OrdinalEncoder\n",
        "from sklearn.impute import SimpleImputer\n",
        "from sklearn.compose import ColumnTransformer\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.metrics import classification_report, accuracy_score\n",
        "from xgboost import XGBClassifier\n",
        "from joblib import dump\n",
        "\n",
        "# =========================================================\n",
        "# 1. Load data\n",
        "# =========================================================\n",
        "csv_path = \"ADNI_MERGE_processed.csv\"   # make sure the file is here or use full path\n",
        "df = pd.read_csv(csv_path)\n",
        "\n",
        "print(\"Shape:\", df.shape)\n",
        "print(\"Columns:\", list(df.columns))\n",
        "\n",
        "# =========================================================\n",
        "# 2. Choose target column & (optionally) drop ID/meta columns\n",
        "# =========================================================\n",
        "TARGET_COL = \"DX\"   # change to \"DIAGNOSIS\" if needed\n",
        "\n",
        "# If you later discover any \"ID-like\" columns here, add them to this list\n",
        "ID_COLUMNS = [\n",
        "    # e.g. \"RID\", \"PTID\" etc., if they exist in this file\n",
        "]\n",
        "\n",
        "id_cols_present = [c for c in ID_COLUMNS if c in df.columns]\n",
        "\n",
        "y = df[TARGET_COL]\n",
        "X = df.drop(columns=[TARGET_COL] + id_cols_present)\n",
        "\n",
        "print(\"Features shape:\", X.shape)\n",
        "print(\"Target value counts:\")\n",
        "print(y.value_counts())\n",
        "\n",
        "# =========================================================\n",
        "# 3. Encode target labels\n",
        "# =========================================================\n",
        "label_encoder = LabelEncoder()\n",
        "y_enc = label_encoder.fit_transform(y)\n",
        "\n",
        "num_classes = len(label_encoder.classes_)\n",
        "print(\"Number of classes in target:\", num_classes)\n",
        "print(\"Classes:\", label_encoder.classes_)\n",
        "\n",
        "if num_classes <= 2:\n",
        "    objective = \"binary:logistic\"\n",
        "    eval_metric = \"logloss\"\n",
        "else:\n",
        "    objective = \"multi:softprob\"\n",
        "    eval_metric = \"mlogloss\"\n",
        "\n",
        "# =========================================================\n",
        "# 4. Train / test split\n",
        "# =========================================================\n",
        "X_train, X_test, y_train, y_test = train_test_split(\n",
        "    X,\n",
        "    y_enc,\n",
        "    test_size=0.2,\n",
        "    random_state=42,\n",
        "    stratify=y_enc,\n",
        ")\n",
        "\n",
        "# =========================================================\n",
        "# 5. Preprocessing: numeric & categorical\n",
        "# =========================================================\n",
        "numeric_cols = X.select_dtypes(include=[\"number\"]).columns.tolist()\n",
        "categorical_cols = X.select_dtypes(exclude=[\"number\"]).columns.tolist()\n",
        "\n",
        "print(\"Numeric columns:\", len(numeric_cols))\n",
        "print(\"Categorical columns:\", len(categorical_cols))\n",
        "\n",
        "numeric_transformer = SimpleImputer(strategy=\"median\")\n",
        "\n",
        "categorical_transformer = Pipeline(\n",
        "    steps=[\n",
        "        (\"imputer\", SimpleImputer(strategy=\"most_frequent\")),\n",
        "        (\"encoder\", OrdinalEncoder(handle_unknown=\"use_encoded_value\", unknown_value=-1)),\n",
        "    ]\n",
        ")\n",
        "\n",
        "preprocessor = ColumnTransformer(\n",
        "    transformers=[\n",
        "        (\"num\", numeric_transformer, numeric_cols),\n",
        "        (\"cat\", categorical_transformer, categorical_cols),\n",
        "    ]\n",
        ")\n",
        "\n",
        "# =========================================================\n",
        "# 6. XGBoost model\n",
        "# =========================================================\n",
        "xgb_params = dict(\n",
        "    n_estimators=500,\n",
        "    learning_rate=0.05,\n",
        "    max_depth=5,\n",
        "    subsample=0.8,\n",
        "    colsample_bytree=0.8,\n",
        "    objective=objective,\n",
        "    eval_metric=eval_metric,\n",
        "    tree_method=\"hist\",    # use \"gpu_hist\" if you have GPU\n",
        "    n_jobs=-1,\n",
        "    random_state=42,\n",
        ")\n",
        "\n",
        "if num_classes > 2:\n",
        "    xgb_params[\"num_class\"] = num_classes\n",
        "\n",
        "xgb_model = XGBClassifier(**xgb_params)\n",
        "\n",
        "clf = Pipeline(\n",
        "    steps=[\n",
        "        (\"preprocess\", preprocessor),\n",
        "        (\"model\", xgb_model),\n",
        "    ]\n",
        ")\n",
        "\n",
        "# =========================================================\n",
        "# 7. Train\n",
        "# =========================================================\n",
        "print(\"\\nTraining XGBoost model on ADNI_MERGE_processed.csv...\")\n",
        "clf.fit(X_train, y_train)\n",
        "\n",
        "# =========================================================\n",
        "# 8. Evaluate\n",
        "# =========================================================\n",
        "print(\"\\nEvaluating on test set...\")\n",
        "y_pred_enc = clf.predict(X_test)\n",
        "\n",
        "print(\"\\nAccuracy:\", accuracy_score(y_test, y_pred_enc))\n",
        "\n",
        "print(\"\\nClass mapping (encoded -> original DX value):\")\n",
        "for i, cls in enumerate(label_encoder.classes_):\n",
        "    print(f\"{i} -> {cls}\")\n",
        "\n",
        "# Convert class names to strings for classification_report\n",
        "class_names = [str(c) for c in label_encoder.classes_]\n",
        "\n",
        "print(\"\\nClassification report:\")\n",
        "print(\n",
        "    classification_report(\n",
        "        y_test,\n",
        "        y_pred_enc,\n",
        "        target_names=class_names\n",
        "    )\n",
        ")\n",
        "\n",
        "# =========================================================\n",
        "# 9. Save model + encoder\n",
        "# =========================================================\n",
        "dump(clf, \"adni_processed_xgb_pipeline.joblib\")\n",
        "dump(label_encoder, \"adni_processed_label_encoder.joblib\")\n",
        "print(\"\\nSaved pipeline to 'adni_processed_xgb_pipeline.joblib' and label encoder to 'adni_processed_label_encoder.joblib'.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UR43ubypTrWt",
        "outputId": "69194340-b61b-471f-ea24-4602e7c695ea"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Shape: (16421, 115)\n",
            "Columns: ['COLPROT', 'ORIGPROT', 'EXAMDATE', 'DX_bl', 'AGE', 'PTGENDER', 'PTEDUCAT', 'PTMARRY', 'APOE4', 'FDG', 'PIB', 'AV45', 'FBB', 'ABETA', 'TAU', 'PTAU', 'CDRSB', 'ADAS11', 'ADAS13', 'ADASQ4', 'MMSE', 'RAVLT_immediate', 'RAVLT_learning', 'RAVLT_forgetting', 'RAVLT_perc_forgetting', 'LDELTOTAL', 'DIGITSCOR', 'TRABSCOR', 'FAQ', 'MOCA', 'EcogPtMem', 'EcogPtLang', 'EcogPtVisspat', 'EcogPtPlan', 'EcogPtOrgan', 'EcogPtDivatt', 'EcogPtTotal', 'EcogSPMem', 'EcogSPLang', 'EcogSPVisspat', 'EcogSPPlan', 'EcogSPOrgan', 'EcogSPDivatt', 'EcogSPTotal', 'FLDSTRENG', 'FSVERSION', 'Ventricles', 'Hippocampus', 'WholeBrain', 'Entorhinal', 'Fusiform', 'MidTemp', 'ICV', 'DX', 'mPACCdigit', 'mPACCtrailsB', 'EXAMDATE_bl', 'CDRSB_bl', 'ADAS11_bl', 'ADAS13_bl', 'ADASQ4_bl', 'MMSE_bl', 'RAVLT_immediate_bl', 'RAVLT_learning_bl', 'RAVLT_forgetting_bl', 'RAVLT_perc_forgetting_bl', 'LDELTOTAL_BL', 'DIGITSCOR_bl', 'TRABSCOR_bl', 'FAQ_bl', 'mPACCdigit_bl', 'mPACCtrailsB_bl', 'FLDSTRENG_bl', 'FSVERSION_bl', 'Ventricles_bl', 'Hippocampus_bl', 'WholeBrain_bl', 'Entorhinal_bl', 'Fusiform_bl', 'MidTemp_bl', 'ICV_bl', 'MOCA_bl', 'EcogPtMem_bl', 'EcogPtLang_bl', 'EcogPtVisspat_bl', 'EcogPtPlan_bl', 'EcogPtOrgan_bl', 'EcogPtDivatt_bl', 'EcogPtTotal_bl', 'EcogSPMem_bl', 'EcogSPLang_bl', 'EcogSPVisspat_bl', 'EcogSPPlan_bl', 'EcogSPOrgan_bl', 'EcogSPDivatt_bl', 'EcogSPTotal_bl', 'ABETA_bl', 'TAU_bl', 'PTAU_bl', 'FDG_bl', 'PIB_bl', 'AV45_bl', 'FBB_bl', 'Years_bl', 'Month_bl', 'update_stamp', 'PTETHCAT_Not Hisp/Latino', 'PTETHCAT_Unknown', 'PTRACCAT_Asian', 'PTRACCAT_Black', 'PTRACCAT_Hawaiian/Other PI', 'PTRACCAT_More than one', 'PTRACCAT_Unknown', 'PTRACCAT_White', 'VISCODE_num']\n",
            "Features shape: (16421, 114)\n",
            "Target value counts:\n",
            "DX\n",
            " 0.752590    9952\n",
            "-1.603837    4020\n",
            "-0.425623    2449\n",
            "Name: count, dtype: int64\n",
            "Number of classes in target: 3\n",
            "Classes: [-1.60383703 -0.42562346  0.7525901 ]\n",
            "Numeric columns: 102\n",
            "Categorical columns: 12\n",
            "\n",
            "Training XGBoost model on ADNI_MERGE_processed.csv...\n",
            "\n",
            "Evaluating on test set...\n",
            "\n",
            "Accuracy: 0.9601217656012176\n",
            "\n",
            "Class mapping (encoded -> original DX value):\n",
            "0 -> -1.6038370303305098\n",
            "1 -> -0.4256234627978609\n",
            "2 -> 0.7525901047347879\n",
            "\n",
            "Classification report:\n",
            "                     precision    recall  f1-score   support\n",
            "\n",
            "-1.6038370303305098       0.97      0.95      0.96       804\n",
            "-0.4256234627978609       0.93      0.93      0.93       490\n",
            " 0.7525901047347879       0.96      0.97      0.97      1991\n",
            "\n",
            "           accuracy                           0.96      3285\n",
            "          macro avg       0.95      0.95      0.95      3285\n",
            "       weighted avg       0.96      0.96      0.96      3285\n",
            "\n",
            "\n",
            "Saved pipeline to 'adni_processed_xgb_pipeline.joblib' and label encoder to 'adni_processed_label_encoder.joblib'.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Random Forest:**"
      ],
      "metadata": {
        "id": "-9mbUKfMVDao"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import LabelEncoder, OrdinalEncoder\n",
        "from sklearn.impute import SimpleImputer\n",
        "from sklearn.compose import ColumnTransformer\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.metrics import classification_report, accuracy_score\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from joblib import dump\n",
        "\n",
        "# =========================================================\n",
        "# 1. Load data\n",
        "# =========================================================\n",
        "csv_path = \"ADNI_MERGE_processed.csv\"\n",
        "df = pd.read_csv(csv_path)\n",
        "\n",
        "print(\"Shape:\", df.shape)\n",
        "print(\"Columns:\", list(df.columns))\n",
        "\n",
        "# =========================================================\n",
        "# 2. Target + (optional) ID columns\n",
        "# =========================================================\n",
        "TARGET_COL = \"DX\"\n",
        "\n",
        "ID_COLUMNS = [\n",
        "    # Add any ID-like columns here if present (e.g. \"RID\", \"PTID\", etc.)\n",
        "]\n",
        "\n",
        "id_cols_present = [c for c in ID_COLUMNS if c in df.columns]\n",
        "\n",
        "y = df[TARGET_COL]\n",
        "X = df.drop(columns=[TARGET_COL] + id_cols_present)\n",
        "\n",
        "print(\"Features shape:\", X.shape)\n",
        "print(\"Target value counts:\")\n",
        "print(y.value_counts())\n",
        "\n",
        "# =========================================================\n",
        "# 3. Encode target\n",
        "# =========================================================\n",
        "label_encoder = LabelEncoder()\n",
        "y_enc = label_encoder.fit_transform(y)\n",
        "\n",
        "print(\"Number of classes:\", len(label_encoder.classes_))\n",
        "print(\"Classes:\", label_encoder.classes_)\n",
        "\n",
        "# =========================================================\n",
        "# 4. Train / test split\n",
        "# =========================================================\n",
        "X_train, X_test, y_train, y_test = train_test_split(\n",
        "    X,\n",
        "    y_enc,\n",
        "    test_size=0.2,\n",
        "    random_state=42,\n",
        "    stratify=y_enc\n",
        ")\n",
        "\n",
        "# =========================================================\n",
        "# 5. Preprocessing\n",
        "# =========================================================\n",
        "numeric_cols = X.select_dtypes(include=[\"number\"]).columns.tolist()\n",
        "categorical_cols = X.select_dtypes(exclude=[\"number\"]).columns.tolist()\n",
        "\n",
        "print(\"Numeric columns:\", len(numeric_cols))\n",
        "print(\"Categorical columns:\", len(categorical_cols))\n",
        "\n",
        "numeric_transformer = SimpleImputer(strategy=\"median\")\n",
        "\n",
        "categorical_transformer = Pipeline(\n",
        "    steps=[\n",
        "        (\"imputer\", SimpleImputer(strategy=\"most_frequent\")),\n",
        "        (\"encoder\", OrdinalEncoder(handle_unknown=\"use_encoded_value\", unknown_value=-1)),\n",
        "    ]\n",
        ")\n",
        "\n",
        "preprocessor = ColumnTransformer(\n",
        "    transformers=[\n",
        "        (\"num\", numeric_transformer, numeric_cols),\n",
        "        (\"cat\", categorical_transformer, categorical_cols),\n",
        "    ]\n",
        ")\n",
        "\n",
        "# =========================================================\n",
        "# 6. Random Forest model\n",
        "# =========================================================\n",
        "rf_model = RandomForestClassifier(\n",
        "    n_estimators=300,\n",
        "    max_depth=None,\n",
        "    min_samples_split=2,\n",
        "    min_samples_leaf=1,\n",
        "    max_features=\"sqrt\",\n",
        "    n_jobs=-1,\n",
        "    random_state=42,\n",
        "    class_weight=\"balanced\"\n",
        ")\n",
        "\n",
        "clf = Pipeline(\n",
        "    steps=[\n",
        "        (\"preprocess\", preprocessor),\n",
        "        (\"model\", rf_model),\n",
        "    ]\n",
        ")\n",
        "\n",
        "# =========================================================\n",
        "# 7. Train\n",
        "# =========================================================\n",
        "print(\"\\nTraining Random Forest on ADNI_MERGE_processed.csv ...\")\n",
        "clf.fit(X_train, y_train)\n",
        "\n",
        "# =========================================================\n",
        "# 8. Evaluate\n",
        "# =========================================================\n",
        "print(\"\\nEvaluating on test set...\")\n",
        "y_pred_enc = clf.predict(X_test)\n",
        "\n",
        "print(\"\\nAccuracy:\", accuracy_score(y_test, y_pred_enc))\n",
        "\n",
        "print(\"\\nClass mapping (encoded -> original DX value):\")\n",
        "for i, cls in enumerate(label_encoder.classes_):\n",
        "    print(f\"{i} -> {cls}\")\n",
        "\n",
        "# Convert class names to strings for classification_report\n",
        "class_names = [str(c) for c in label_encoder.classes_]\n",
        "\n",
        "print(\"\\nClassification report:\")\n",
        "print(\n",
        "    classification_report(\n",
        "        y_test,\n",
        "        y_pred_enc,\n",
        "        target_names=class_names\n",
        "    )\n",
        ")\n",
        "\n",
        "# =========================================================\n",
        "# 9. Save model + encoder\n",
        "# =========================================================\n",
        "dump(clf, \"rf_adni_processed_pipeline.joblib\")\n",
        "dump(label_encoder, \"rf_adni_processed_label_encoder.joblib\")\n",
        "print(\"\\nSaved pipeline to 'rf_adni_processed_pipeline.joblib' and label encoder to 'rf_adni_processed_label_encoder.joblib'.\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "t0d-XjH6VGb4",
        "outputId": "2167f735-1449-43b7-915b-e185732ed9da"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Shape: (16421, 115)\n",
            "Columns: ['COLPROT', 'ORIGPROT', 'EXAMDATE', 'DX_bl', 'AGE', 'PTGENDER', 'PTEDUCAT', 'PTMARRY', 'APOE4', 'FDG', 'PIB', 'AV45', 'FBB', 'ABETA', 'TAU', 'PTAU', 'CDRSB', 'ADAS11', 'ADAS13', 'ADASQ4', 'MMSE', 'RAVLT_immediate', 'RAVLT_learning', 'RAVLT_forgetting', 'RAVLT_perc_forgetting', 'LDELTOTAL', 'DIGITSCOR', 'TRABSCOR', 'FAQ', 'MOCA', 'EcogPtMem', 'EcogPtLang', 'EcogPtVisspat', 'EcogPtPlan', 'EcogPtOrgan', 'EcogPtDivatt', 'EcogPtTotal', 'EcogSPMem', 'EcogSPLang', 'EcogSPVisspat', 'EcogSPPlan', 'EcogSPOrgan', 'EcogSPDivatt', 'EcogSPTotal', 'FLDSTRENG', 'FSVERSION', 'Ventricles', 'Hippocampus', 'WholeBrain', 'Entorhinal', 'Fusiform', 'MidTemp', 'ICV', 'DX', 'mPACCdigit', 'mPACCtrailsB', 'EXAMDATE_bl', 'CDRSB_bl', 'ADAS11_bl', 'ADAS13_bl', 'ADASQ4_bl', 'MMSE_bl', 'RAVLT_immediate_bl', 'RAVLT_learning_bl', 'RAVLT_forgetting_bl', 'RAVLT_perc_forgetting_bl', 'LDELTOTAL_BL', 'DIGITSCOR_bl', 'TRABSCOR_bl', 'FAQ_bl', 'mPACCdigit_bl', 'mPACCtrailsB_bl', 'FLDSTRENG_bl', 'FSVERSION_bl', 'Ventricles_bl', 'Hippocampus_bl', 'WholeBrain_bl', 'Entorhinal_bl', 'Fusiform_bl', 'MidTemp_bl', 'ICV_bl', 'MOCA_bl', 'EcogPtMem_bl', 'EcogPtLang_bl', 'EcogPtVisspat_bl', 'EcogPtPlan_bl', 'EcogPtOrgan_bl', 'EcogPtDivatt_bl', 'EcogPtTotal_bl', 'EcogSPMem_bl', 'EcogSPLang_bl', 'EcogSPVisspat_bl', 'EcogSPPlan_bl', 'EcogSPOrgan_bl', 'EcogSPDivatt_bl', 'EcogSPTotal_bl', 'ABETA_bl', 'TAU_bl', 'PTAU_bl', 'FDG_bl', 'PIB_bl', 'AV45_bl', 'FBB_bl', 'Years_bl', 'Month_bl', 'update_stamp', 'PTETHCAT_Not Hisp/Latino', 'PTETHCAT_Unknown', 'PTRACCAT_Asian', 'PTRACCAT_Black', 'PTRACCAT_Hawaiian/Other PI', 'PTRACCAT_More than one', 'PTRACCAT_Unknown', 'PTRACCAT_White', 'VISCODE_num']\n",
            "Features shape: (16421, 114)\n",
            "Target value counts:\n",
            "DX\n",
            " 0.752590    9952\n",
            "-1.603837    4020\n",
            "-0.425623    2449\n",
            "Name: count, dtype: int64\n",
            "Number of classes: 3\n",
            "Classes: [-1.60383703 -0.42562346  0.7525901 ]\n",
            "Numeric columns: 102\n",
            "Categorical columns: 12\n",
            "\n",
            "Training Random Forest on ADNI_MERGE_processed.csv ...\n",
            "\n",
            "Evaluating on test set...\n",
            "\n",
            "Accuracy: 0.9482496194824962\n",
            "\n",
            "Class mapping (encoded -> original DX value):\n",
            "0 -> -1.6038370303305098\n",
            "1 -> -0.4256234627978609\n",
            "2 -> 0.7525901047347879\n",
            "\n",
            "Classification report:\n",
            "                     precision    recall  f1-score   support\n",
            "\n",
            "-1.6038370303305098       0.97      0.93      0.95       804\n",
            "-0.4256234627978609       0.93      0.88      0.90       490\n",
            " 0.7525901047347879       0.94      0.97      0.96      1991\n",
            "\n",
            "           accuracy                           0.95      3285\n",
            "          macro avg       0.95      0.93      0.94      3285\n",
            "       weighted avg       0.95      0.95      0.95      3285\n",
            "\n",
            "\n",
            "Saved pipeline to 'rf_adni_processed_pipeline.joblib' and label encoder to 'rf_adni_processed_label_encoder.joblib'.\n"
          ]
        }
      ]
    }
  ]
}